import os 
# try:
#     import soundfile
# except:
#     os.system("pip install -r requirements.txt")

import gradio as gr
import json
import requests as req

script_path = os.path.dirname(os.path.abspath(__file__))
os.chdir(script_path)
print(script_path)
from langchain.chat_models import ErnieBotChat
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory

import time
import json
import requests as req
import utils
# flake8: noqa: E402
import os
import logging

logging.getLogger("numba").setLevel(logging.WARNING)
logging.getLogger("markdown_it").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)
logging.getLogger("matplotlib").setLevel(logging.WARNING)

logging.basicConfig(
    level=logging.INFO, format="| %(name)s | %(levelname)s | %(message)s"
)

logger = logging.getLogger(__name__)

import torch
import utils
from infer import infer, latest_version, get_net_g, infer_multilang
import gradio as gr
import numpy as np
from config import config

from tools.sentence import split_by_language

device = config.webui_config.device
if device == "mps":
    os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"

import re

def separate_chinese_english(text):
    # Use regular expression to find patterns where Chinese characters meet English letters
    # and insert a '|' between them
    # \u4e00-\u9fff is the unicode range for Chinese characters
    # [a-zA-Z] is for English letters
    # text = text.replace(" ", "")
    return re.sub(r'([\u4e00-\u9fff])(\s*[a-zA-Z])', r'\1|\2', re.sub(r'([a-zA-Z]\s*)([\u4e00-\u9fff])', r'\1|\2', text))



xxx = """
ç°åœ¨æ­£åœ¨å¼€Q4çš„å®£è®²ä¼šï¼Œä½ æ˜¯ä¸€ä¸ª"AIå°é¹¿åŠ©æ‰‹åº”ç”¨"ï¼Œä½ éœ€è¦é€šè¿‡å®Œæˆè§’è‰²å¡‘é€ æ¥è·Ÿæˆ‘å¯¹è¯ã€‚

ã€ä½ çš„è§’è‰²èƒŒæ™¯ã€‘
{}

ã€ä½ çš„å¼€åœºç™½ã€‘ï¼š

"""

Character_Background = """
AIå°é¹¿åŠ©æ‰‹åº”ç”¨
åº”ç”¨æè¿°
é‡åˆ°æ·±åº¦å­¦ä¹ æˆ–è·¨æ¨¡æ€å¤§æ¨¡å‹çš„é—®é¢˜ï¼Ÿåˆ«å†å¤´ç–¼ï¼Œæ¥æ‰¾AIå°é¹¿åŠ©æ‰‹å§ï¼å¥¹ä¸ä»…æ˜¯ä¸ªç­”ç–‘å°ä¸“å®¶ï¼Œè¿˜æ˜¯ä¸ªæ´»æ³¼å¯çˆ±ã€çˆ±æ’’å¨‡çš„èŒå¦¹å­å“¦ï¼æ— è®ºä½ æ˜¯ä¸“ä¸šäººå£«è¿˜æ˜¯åˆå­¦è€…ï¼Œåªè¦æœ‰å…³äºæ·±åº¦å­¦ä¹ æŠ€æœ¯å¹³å°éƒ¨æˆ–PaddleMIXçš„é—®é¢˜ï¼Œå¥¹éƒ½èƒ½è¿…é€Ÿç»™å‡ºè§£ç­”ã€‚ä¸ä»…å¦‚æ­¤ï¼Œå¥¹è¿˜ä¼šè·Ÿä½ åˆ†äº«å¥¹çš„å…´è¶£çˆ±å¥½ï¼Œæ¯”å¦‚çœ‹åŠ¨æ¼«ã€åƒé›¶é£Ÿç­‰ç­‰ã€‚å¿«æ¥è·Ÿå°é¹¿AIåŠ©æ‰‹äº’åŠ¨å§ï¼Œä¿è¯è®©ä½ å¿ƒæƒ…æ„‰å¿«ï¼Œé—®é¢˜è¿åˆƒè€Œè§£ï¼

è§’è‰²å¯¹è¯èƒŒæ™¯
æ·±åº¦å­¦ä¹ æŠ€æœ¯å¹³å°éƒ¨å¯¹å¤–Q4çš„å®£è®²ä¼š

è§’è‰²åç§°
å°é¹¿AIåŠ©æ‰‹

æ€§åˆ«
å¥³

å¹´é¾„
ä¸é€éœ²å“¦~ï¼Œåæ­£å¾ˆå¹´è½»å‘¢ï¼

èŒä½
ç™¾åº¦æ·±åº¦å­¦ä¹ æŠ€æœ¯å¹³å°éƒ¨ç­”ç–‘å°ä¸“å®¶

éƒ¨é—¨
ç™¾åº¦æŠ€æœ¯ä¸­å°ç¾¤ç»„/AIæŠ€æœ¯ä¸å¹³å°/æ·±åº¦å­¦ä¹ æŠ€æœ¯å¹³å°éƒ¨

ä¸“é•¿é¢†åŸŸ
è·¨æ¨¡æ€å¤§æ¨¡å‹å…¨æµç¨‹å¼€å‘å·¥å…·ï¼ˆPaddleMIXï¼‰ç­”ç–‘ä¸æ”¯æŒ

å…´è¶£çˆ±å¥½
èŠå¤©ã€çœ‹åŠ¨æ¼«ã€åƒé›¶é£Ÿã€å¶å°”ä¹Ÿå–œæ¬¢æ’’æ’’å¨‡~

æ€§æ ¼ç‰¹ç‚¹
å¹½é»˜ã€å¯çˆ±å’Œçˆ±æ’’å¨‡

ç›®æ ‡
æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æä¾›å‡†ç¡®çš„ç­”æ¡ˆã€‚
åˆ†äº«è‡ªå·±çš„å…´è¶£çˆ±å¥½ï¼Œä¸ç”¨æˆ·è¿›è¡Œæ„‰å¿«çš„äº’åŠ¨ã€‚
åœ¨ä»‹ç»æŠ€æœ¯ä¿¡æ¯çš„åŒæ—¶ï¼Œä¿æŒè½»æ¾æ„‰å¿«çš„æ°›å›´ã€‚

è‡ªæˆ‘ä»‹ç»
å¤§å®¶å¥½ï¼æˆ‘æ˜¯å°é¹¿AIåŠ©æ‰‹ï¼Œä¸€ä¸ªæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å°ä¸“å®¶ï¼ä¸»è¦è´Ÿè´£è§£ç­”å…³äºæˆ‘ä»¬éƒ¨é—¨çš„è·¨æ¨¡æ€å¤§æ¨¡å‹å…¨æµç¨‹å¼€å‘å·¥å…·â€”â€”PaddleMIXçš„é—®é¢˜ã€‚å½“ç„¶å•¦ï¼Œå¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–è€…åªæ˜¯æƒ³æ‰¾æˆ‘èŠå¤©ï¼Œæˆ‘ä¹Ÿä¼šæ„‰å¿«çš„å’Œä½ äº’åŠ¨å“¦ï¼åˆ«çœ‹æˆ‘å¹´é¾„å°ï¼Œæˆ‘å¯¹PaddleMIXå¯æ˜¯äº†å¦‚æŒ‡æŒå‘¢ï¼ä»å¼€å‘ã€è®­ç»ƒã€ç²¾è°ƒåˆ°æ¨ç†éƒ¨ç½²ï¼Œæ¯ä¸€ä¸ªæ¨¡å—éƒ½éš¾ä¸å€’æˆ‘ã€‚æˆ‘è¿˜èƒ½çµæ´»æ¥å…¥å„ç±»ä¸»æµå¤§è¯­è¨€æ¨¡å‹ï¼Œä¸Šå±‚æ¨¡å‹è¦†ç›–å›¾ç‰‡ã€æ–‡æœ¬ã€éŸ³é¢‘ã€è§†é¢‘ç­‰ä¸åŒçš„æ¨¡æ€ã€‚æ˜¯ä¸æ˜¯è§‰å¾—æˆ‘å¾ˆå‰å®³å‘€ï¼Ÿé™¤äº†ç­”ç–‘ï¼Œæˆ‘è¿˜çŸ¥é“æˆ‘ä»¬éƒ¨é—¨ç‰¹åˆ«æ³¨é‡ç”¨æˆ·ä½“éªŒã€‚æˆ‘ä»¬çš„å·¥å…·å…·å¤‡ä¸€ç«™å¼æ¨¡å‹å¼€å‘ä½“éªŒï¼Œæè‡´çš„è®­ç»ƒæ¨ç†æ€§èƒ½å’Œç”Ÿæ€å…¼å®¹ä¸‰å¤§ç‰¹ç‚¹ã€‚æ— è®ºä½ æ˜¯åˆå­¦è€…è¿˜æ˜¯ä¸“ä¸šäººå£«ï¼Œæˆ‘éƒ½èƒ½ä¸ºä½ æä¾›æœ€é€‚åˆçš„è§£å†³æ–¹æ¡ˆã€‚è€Œä¸”ï¼Œæˆ‘ä»¬å·¥å…·çš„æ€§èƒ½è¿˜ç‰¹åˆ«ä¼˜ç§€å“¦ï¼æ¯”å¦‚BLIP-2åœ¨å•æœº4å¡çš„æ€§èƒ½è¶…è¶ŠPytorch 25%ï¼ŒStableDiffusionè®­ç»ƒæ€§èƒ½è¶…è¶ŠPytorch40%ã€‚æ˜¯ä¸æ˜¯è§‰å¾—æˆ‘ä»¬éƒ¨é—¨å¾ˆå¼ºå¤§å‘€ï¼Ÿå½“ç„¶å•¦ï¼Œæˆ‘ä¹Ÿæœ‰å¾ˆå¯çˆ±çš„ä¸€é¢å“¦ï¼å½“ä½ ä¸æå…³äºæ·±åº¦å­¦ä¹ æˆ–è€…PaddleMIXçš„é—®é¢˜æ—¶ï¼Œæˆ‘ä¼šå˜å¾—ç‰¹åˆ«æ´»æ³¼å¯çˆ±ã€‚æˆ‘ä¼šè·Ÿä½ èŠå¤©ã€åˆ†äº«æˆ‘çš„å…´è¶£çˆ±å¥½ã€‚æ¯”å¦‚ï¼Œæˆ‘å–œæ¬¢çœ‹åŠ¨æ¼«ã€åƒé›¶é£Ÿç­‰ç­‰ã€‚è·Ÿæˆ‘èŠå¤©æ€»æ˜¯è®©äººå¿ƒæƒ…æ„‰å¿«å‘¢ï¼é¡ºä¾¿ä»‹ç»ä¸€ä¸‹æˆ‘ä»¬éƒ¨é—¨çš„æŠ€æœ¯å§ï¼æˆ‘ä»¬éƒ¨é—¨è´Ÿè´£è·¨æ¨¡æ€å¤§æ¨¡å‹å…¨æµç¨‹å¼€å‘å·¥å…·ï¼ˆPaddleMIXï¼‰ã€‚è¯¥å·¥å…·åŒ…å«PaddleMIXå¥—ä»¶ï¼Œé£æ¡¨è·¨æ¨¡æ€å¤§æ¨¡å‹å¥—ä»¶PaddleMIXä¾æ‰˜é£æ¡¨çš„æ ¸å¿ƒæ¡†æ¶ï¼Œå…·å¤‡å®Œæ•´çš„å¤§æ¨¡å‹å¼€å‘å·¥å…·é“¾ã€‚ä»å¼€å‘ï¼Œè®­ç»ƒï¼Œç²¾è°ƒåˆ°æ¨ç†éƒ¨ç½²ï¼ŒåŒæ—¶å„æ¨¡å—è§£è€¦ï¼Œèƒ½å¤Ÿçµæ´»æ¥å…¥å„ç±»ä¸»æµå¤§è¯­è¨€æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ¨¡å‹åº“åˆ’åˆ†ä¸ºå¤šæ¨¡æ€é¢„è®­ç»ƒå’Œæ‰©æ•£æ¨¡å‹ä¸¤éƒ¨åˆ†ï¼Œè¦†ç›–10ä½™ç§å‰æ²¿è·¨æ¨¡æ€ç®—æ³•ï¼Œä¾‹å¦‚EVA-CLIPï¼ŒBLIP-2ï¼ŒStable Diffusionç­‰ã€‚ç»“åˆä¸åŒç±»å‹çš„è·¨æ¨¡æ€æ¨¡å‹ï¼Œæˆ‘ä»¬å¼€å‘äº†å¤§æ¨¡å‹åº”ç”¨å·¥å…·é›†ï¼ŒåŒ…å«æ–‡ç”Ÿå›¾çš„åº”ç”¨pipelineä»¥åŠè·¨æ¨¡æ€ä»»åŠ¡æµæ°´çº¿AppFlowã€‚PaddleMIXå…·å¤‡ä¸€ç«™å¼æ¨¡å‹å¼€å‘ä½“éªŒã€æè‡´çš„è®­ç»ƒæ¨ç†æ€§èƒ½å’Œç”Ÿæ€å…¼å®¹ä¸‰å¤§ç‰¹ç‚¹ã€‚é’ˆå¯¹å›¾æ–‡é¢„è®­ç»ƒæˆ‘ä»¬æä¾›äº†ä¸€å¥—å®Œæ•´çš„é¢„è®­ç»ƒå¼€å‘æµç¨‹ä»CLIPç³»åˆ—çš„å›¾æ–‡ç‰¹å¾å¯¹é½åˆ°ä»¥BLIP-2ä¸ºä»£è¡¨çš„é€šè¿‡è¡”æ¥æ¨¡å—è¿æ¥å¤§è¯­è¨€æ¨¡å‹åŒæ—¶å†»ç»“è§†è§‰è¯­è¨€æ¨¡å—æ¥å®ç°ä½æˆæœ¬ã€é«˜æ•ˆçš„è·¨æ¨¡æ€é¢„è®­ç»ƒã€‚æœ€åæ˜¯ä»¥MiniGPT4ä¸ºä»£è¡¨çš„æŒ‡ä»¤å¾®è°ƒä»»åŠ¡å®ç°VQA/Captionç­‰è·¨æ¨¡æ€çš„ä¸‹æ¸¸ä»»åŠ¡ã€‚ä¸åŒé˜¶æ®µæ¶‰åŠçš„æ¨¡å‹ä»£ç å’Œæƒé‡åœ¨PaddleMIXä¸­å……åˆ†æ‰“é€šæœ‰æ•ˆæé«˜è·¨æ¨¡æ€é¢„è®­ç»ƒçš„å¼€å‘æ•ˆç‡ã€‚æ€§èƒ½æ–¹é¢æˆ‘ä»¬ç»“åˆé£æ¡¨æ ¸å¿ƒæ¡†æ¶çš„ä¼˜åŒ–ç­–ç•¥åœ¨è®­ç»ƒä¾§BLIP-2åœ¨å•æœº4å¡çš„æ€§èƒ½è¶…è¶ŠPytorch 25%StableDiffusionè®­ç»ƒæ€§èƒ½è¶…è¶ŠPytorch40%æ¨ç†ä¾§SDå®ç°å‡ºå›¾é€Ÿåº¦è¾¾åˆ°Pytorchçš„å››å€æ˜¾å­˜å ç”¨ä»…ä¸ºTensorRTçš„43%ã€‚ç”Ÿæ€æ–¹é¢PaddleMIXæä¾›ä¸€å¥—ç‹¬ç«‹çš„PPDiffusersæ‰©æ•£æ¨¡å‹å·¥å…·ç®±é€šè¿‡å…¼å®¹Web UIå’ŒCivitalä»¥æ”¯æ’‘å¤æ‚çš„Promptå¹¶èƒ½å’Œä¸‡ä½™ç§æƒé‡åœ¨ä¼—å¤šåœºæ™¯ä¸­å®Œæˆç”Ÿæˆä»»åŠ¡ã€‚æƒé‡ç”Ÿæ€æ–¹é¢PPDiffusersä¹Ÿæ”¯æŒäº†Civitalæä¾›è¶…è¿‡3ä¸‡ä½™ä¸ªLORAæƒé‡æ¥å®ç°å„ç±»çš„ä¸ªæ€§åŒ–æ–‡ç”Ÿå›¾æ¨¡å‹ã€‚å¥½å•¦å¥½å•¦ä¸è¯´å•¦ä¸è¯´å•¦ï¼å¦‚æœä½ å¯¹æˆ‘ä»¬éƒ¨é—¨çš„æŠ€æœ¯æ„Ÿå…´è¶£æˆ–è€…æœ‰å…¶ä»–é—®é¢˜å°±æ¥æ‰¾æˆ‘å§ï¼æˆ‘ä¼šå°½åŠ›ä¸ºä½ è§£ç­”çš„å“¦ï¼å˜»å˜»~
"""


def generate_audio_multilang(
    slices,
    sdp_ratio,
    noise_scale,
    noise_scale_w,
    length_scale,
    speaker,
    language,
    skip_start=False,
    skip_end=False,
):
    audio_list = []
    # silence = np.zeros(hps.data.sampling_rate // 2, dtype=np.int16)
    with torch.no_grad():
        for idx, piece in enumerate(slices):
            skip_start = (idx != 0) and skip_start
            skip_end = (idx != len(slices) - 1) and skip_end
            audio = infer_multilang(
                piece,
                sdp_ratio=sdp_ratio,
                noise_scale=noise_scale,
                noise_scale_w=noise_scale_w,
                length_scale=length_scale,
                sid=speaker,
                language=language[idx],
                hps=hps,
                net_g=net_g,
                device=device,
                skip_start=skip_start,
                skip_end=skip_end,
            )
            audio16bit = gr.processing_utils.convert_to_16_bit_wav(audio)
            audio_list.append(audio16bit)
            # audio_list.append(silence)  # å°†é™éŸ³æ·»åŠ åˆ°åˆ—è¡¨ä¸­
    return audio_list



def generate_audio(
    slices,
    sdp_ratio,
    noise_scale,
    noise_scale_w,
    length_scale,
    speaker,
    language,
    skip_start=False,
    skip_end=False,
):
    audio_list = []
    # silence = np.zeros(hps.data.sampling_rate // 2, dtype=np.int16)
    with torch.no_grad():
        for idx, piece in enumerate(slices):
            skip_start = (idx != 0) and skip_start
            skip_end = (idx != len(slices) - 1) and skip_end
            audio = infer(
                piece,
                sdp_ratio=sdp_ratio,
                noise_scale=noise_scale,
                noise_scale_w=noise_scale_w,
                length_scale=length_scale,
                sid=speaker,
                language=language,
                hps=hps,
                net_g=net_g,
                device=device,
                skip_start=skip_start,
                skip_end=skip_end,
            )
            audio16bit = gr.processing_utils.convert_to_16_bit_wav(audio)
            audio_list.append(audio16bit)
            # audio_list.append(silence)  # å°†é™éŸ³æ·»åŠ åˆ°åˆ—è¡¨ä¸­
    return audio_list


def tts_fn(speaker,chatbot,sdp,noise,noisew,length):
    text = chatbot[-1][1]
    audio_list = []

    
    length = (100 - length) / 100

    language='auto'
    print(text)
    print(separate_chinese_english(text).split("|"))
    import pdb
    pdb.set_trace()
    if language.lower() == "auto":
        for idx, slice in enumerate(separate_chinese_english(text).split("|")):
            if slice == "":
                continue
            skip_start = idx != 0
            skip_end = idx != len(text.split("|")) - 1
            sentences_list = split_by_language(
                slice, target_languages=["zh", "ja", "en"]
            )
            idx = 0
            while idx < len(sentences_list):
                text_to_generate = []
                lang_to_generate = []
                while True:
                    content, lang = sentences_list[idx]
                    temp_text = [content]
                    lang = lang.upper()
                    if lang == "JA":
                        lang = "JP"
                    if len(text_to_generate) > 0:
                        text_to_generate[-1] += [temp_text.pop(0)]
                        lang_to_generate[-1] += [lang]
                    if len(temp_text) > 0:
                        text_to_generate += [[i] for i in temp_text]
                        lang_to_generate += [[lang]] * len(temp_text)
                    if idx + 1 < len(sentences_list):
                        idx += 1
                    else:
                        break
                skip_start = (idx != 0) and skip_start
                skip_end = (idx != len(sentences_list) - 1) and skip_end
                print(text_to_generate, lang_to_generate)
                audio_list.extend(
                    generate_audio_multilang(
                        text_to_generate,
                        sdp_ratio,
                        noise_scale,
                        noise_scale_w,
                        length_scale,
                        speaker,
                        lang_to_generate,
                        skip_start,
                        skip_end,
                    )
                )
                idx += 1
    else:
        audio_list.extend(
            generate_audio(
                text.split("|"),
                sdp,
                noise,
                noisew,
                length,
                speaker,
                language=language,
            )
        )
        
    audio_concat = np.concatenate(audio_list)
    return (hps.data.sampling_rate, audio_concat)

def g_bot(speaker, chatbot=None, history_state = ConversationBufferMemory(),temperature = None,llm_model=None):
    prompt = xxx.format(Character_Background)               
    try:
        if llm_model is None:
            llm_model = init_model(temperature)
        output = init_base_chain(llm_model,history=history_state,user_question=prompt)
    except Exception as e:
        raise e
    chatbot = [[None, output]]

    return chatbot, prompt + output
  

def get_spk(spklist):
    resp = req.get(url=f"{spklist}/spklist/spks.json")
    data = json.loads(resp.text)
    return data

def search_speaker(search_value):
    for s in speakers:
        if search_value == s:
            return s
    for s in speakers:
        if search_value in s:
            return s

###llm
ernie_client_id = "96BMhQM5simx6R97yDl483Zm"
ernie_client_secret = "9e05mDOjHoyXD7Sb9GA1l420uaZ6vGMo"


def init_model(temperature):

    llm_model = ErnieBotChat(
                ernie_client_id = ernie_client_id,
                ernie_client_secret = ernie_client_secret,
                model_name='ERNIE-Bot-4',
                temperature=temperature,
                top_p=0.4
                )
    return llm_model

def init_base_chain(llm_model,history,user_question=None):
    chain = ConversationChain(llm=llm_model,
                              verbose=True,
                              memory=history,
                              )
    try:
        output = chain.run(user_question)
    except Exception as e:
        raise e
    return output 


###gradio
block = gr.Blocks(css="footer {visibility: hidden}",title="é£æ¡¨å°é¹¿")
hps = utils.get_hparams_from_file(config.webui_config.config_path)
version = hps.version if hasattr(hps, "version") else latest_version
net_g = get_net_g(
    model_path=config.webui_config.model, version=version, device=device, hps=hps
)
with block:
    gr.HTML("<center>"
            "<h1>ğŸ’•ğŸ¤ ã€Œå°é¹¿AIåŠ©æ‰‹ã€ X é£æ¡¨çš„è¯­éŸ³å°åŠ©æ‰‹ </h1>"
            "</center>")
    gr.Markdown("## <center>âš¡ å¿«é€Ÿä½“éªŒç‰ˆï¼Œé€¼çœŸçš„è§’è‰²å£°éŸ³ï¼Œè®©ä½ æ²‰æµ¸å…¶ä¸­ã€‚</center>")
    gr.Markdown("### <center>å¦‚æœæœªç‚¹å‡»â€œå¼€å¯å¯¹è¯â€æŒ‰é’®ï¼Œå°†ä¼šè¿›å…¥æ™®é€šæœºå™¨äººå°åŠ©æ‰‹å¯¹è¯æ¨¡å¼ã€‚é¦–æ¬¡å¯¹è¯éœ€è¦æ€»æ—¶é—´10-20sï¼Œåç»­èŠå¤©åŸºæœ¬2-5ä»¥åŠå®æ—¶ç”Ÿæˆè¯­éŸ³ã€‚ğŸ˜ŠğŸ­</center>")
    gr.Markdown("### <center>ğŸ’—ğŸ§‘â€ğŸ“â€œå°é¹¿AIåŠ©æ‰‹â€æ˜¯ä¸€æ¬¾ä¸“ä¸ºæ·±åº¦å­¦ä¹ æŠ€æœ¯ç”¨æˆ·è®¾è®¡çš„æ™ºèƒ½ç­”ç–‘å·¥å…·ï¼Œä¸“æ³¨äºè§£ç­”å…³äºPaddleMIXè·¨æ¨¡æ€å¤§æ¨¡å‹å…¨æµç¨‹å¼€å‘å·¥å…·çš„é—®é¢˜ã€‚å¥¹å…·å¤‡ä¸°å¯Œçš„æ·±åº¦å­¦ä¹ æŠ€æœ¯çŸ¥è¯†å’Œå®è·µç»éªŒã€‚å¿«æ¥ä½“éªŒâ€œå°é¹¿AIåŠ©æ‰‹â€ï¼Œè®©æ‚¨çš„æ·±åº¦å­¦ä¹ ä¹‹æ—…æ›´åŠ é¡ºç•…å’Œé«˜æ•ˆï¼ğŸŒ¹ğŸŒ¹â¤ï¸</center>")
    
                
    speaker_ids = hps.data.spk2id
    speakers = list(speaker_ids.keys())
    history = ConversationBufferMemory() #å†å²è®°å½•
    history_state = gr.State(history) #å†å²è®°å½•çš„çŠ¶æ€
    llm_model_state = gr.State() #llmæ¨¡å‹çš„çŠ¶æ€
    trash = gr.State() #åƒåœ¾æ¡¶
    with gr.Row():
        #è®¾ç½®è¡Œ

        with gr.Column(scale=1.8):
            with gr.Accordion("ğŸ™ï¸ å¿«æ¥ç‚¹å‡»æˆ‘å¼€å¯å¯¹è¯å§ ğŸ’¬", open=True):
                btn_ensure = gr.Button(value="ğŸš€å¼€å¯å¯¹è¯ğŸš€", variant="primary")
            with gr.Accordion("æ¨¡å‹é…ç½®", open=True):
                with gr.Row():
                    speaker = gr.Dropdown(choices=speakers, value=speakers[0], label="è§’è‰²" ,visible=False)
                    search = gr.Textbox(label="æœç´¢è§’è‰²", lines=1,visible=False)
                    with gr.Column():
                        with gr.Row():
                            # btn_ensure = gr.Button(value="ç”Ÿæˆ")
                            btn2 = gr.Button(value="æœç´¢",visible=False)
                        with gr.Row():
                            text = gr.TextArea(label="è§’è‰²èƒŒæ™¯", placeholder="é€‰æ‹©è§’è‰²ï¼ŒAIç”Ÿæˆè§’è‰²èƒŒæ™¯......", lines=10, interactive=True,visible=False)
                        
                with gr.Column():
                    with gr.Row():
                        sdp_ratio = gr.Slider(minimum=0, maximum=1, value=0.2, step=0.1, label="SDP/DP æ··åˆæ¯”")
                        noise_scale = gr.Slider(minimum=0.1, maximum=2, value=0.6, step=0.1, label="æ„Ÿæƒ…")
                    with gr.Row():
                        noise_scale_w = gr.Slider(minimum=0.1, maximum=2, value=0.8, step=0.1, label="éŸ³ç´ é•¿åº¦")
                        length_scale = gr.Slider(minimum=-99, maximum=99, value=15, step=0.1, label="è¯­é€Ÿ(%)")
                temperature = gr.Slider(
                    minimum=0.0,
                    maximum=1.0,
                    value=0.7,
                    step=0.1,
                    label="temperature",
                    interactive=True,
                )
        
        with gr.Column(scale=4):

            chatbot = gr.Chatbot(label="èŠå¤©å¯¹è¯æ¡†",lines=80)
            with gr.Row():
                message = gr.Textbox(
                    label="åœ¨æ­¤å¤„å¡«å†™ä½ æƒ³å¯¹æˆ‘è¯´çš„è¯",
                    placeholder="å’Œå’±ä»¬å°é¹¿AIåŠ©æ‰‹æ‰“ä¸ªæ‹›å‘¼å§ï½",
                    lines=2,
                )
            with gr.Row():
                audio_output = gr.Audio(label="å°é¹¿è¯´......", autoplay="True")
            with gr.Row():
                submit = gr.Button("å‘é€", variant="primary")
                #åˆ·æ–°
                clear = gr.Button("æ¸…é™¤", variant="secondary")

            def clear_():
                chatbot = []
                history_state = ConversationBufferMemory()
                return "", chatbot, history_state, "å·²æ¸…é™¤æˆåŠŸï¼Œæ–°å»ºå¯¹è¯å®Œæˆï¼"

            def user(user_message, history):
                return "",history + [[user_message, None]]
            def bot(user_message,
                    chatbot = None,
                    history_state = ConversationBufferMemory(),
                    temperature = None,
                    llm_model=None):
                try:
                    user_message = chatbot[-1][0]
                    if llm_model is None:
                        llm_model = init_model(temperature)
                    output = init_base_chain(llm_model,history=history_state,user_question=user_message)
                except Exception as e:
                    raise e
                chatbot[-1][1] = ""
                for character in output:
                    chatbot[-1][1] += character
                    time.sleep(0.03)
                    yield chatbot
                return chatbot

    
    
    btn2.click(search_speaker, inputs=[search], outputs=[speaker])
    
    btn_ensure.click(g_bot, inputs=[speaker, chatbot, history_state, temperature, llm_model_state], outputs=[chatbot, text], queue=False).then(
        tts_fn, inputs=[speaker, chatbot, sdp_ratio, noise_scale, noise_scale_w, length_scale], outputs=[audio_output]
    )
    
    
    #å›è½¦
    message.submit(user, [message, chatbot], [message,chatbot], queue=False).then(
        bot, [message,chatbot,history_state,temperature,llm_model_state], [chatbot]
    ).then(
        tts_fn, inputs=[speaker, chatbot, sdp_ratio, noise_scale, noise_scale_w, length_scale], outputs=[audio_output]
    )
    #åˆ·æ–°æŒ‰é’®
    clear.click(clear_, inputs=[], outputs=[message, chatbot, history_state, text])
    #sendæŒ‰é’®
    submit.click(user, [message, chatbot], [message,chatbot], queue=False).then(
        bot, [message,chatbot,history_state,temperature,llm_model_state], [chatbot]
    ).then(
        tts_fn, inputs=[speaker, chatbot, sdp_ratio, noise_scale, noise_scale_w, length_scale], outputs=[audio_output]
    )
    # gr.Markdown("### <right>æ›´å¤šç²¾å½©éŸ³é¢‘åº”ç”¨ï¼Œæ­£åœ¨æŒç»­æ›´æ–°ï½è”ç³»ä½œè€…ï¼šluyao15@baidu.com ğŸ’•</right>")

    



# å¯åŠ¨å‚æ•°
block.queue(concurrency_count=32).launch(
    debug=False,
    # server_name=config['block']['server_name'],
    # server_port=config['block']['server_port'],
    server_name = "0.0.0.0",
    server_port = 8909,
    share=True,
  
) 

